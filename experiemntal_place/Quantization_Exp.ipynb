{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "traditional-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "integrated-examination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10, bias=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "        \n",
    "    \n",
    "my_nn = Net()\n",
    "print(my_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "prescription-blair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=512, bias=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nn.linear_relu_stack[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "medium-tattoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0097, -0.0198,  0.0102,  ..., -0.0285,  0.0237,  0.0202],\n",
      "        [-0.0076, -0.0356,  0.0179,  ..., -0.0016,  0.0250, -0.0133]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0158,  0.0197,  0.0352,  ..., -0.0313,  0.0398, -0.0101],\n",
      "        [-0.0334, -0.0011,  0.0299,  ...,  0.0415,  0.0432,  0.0374]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0357, -0.0224,  0.0035,  ...,  0.0009, -0.0207, -0.0197],\n",
      "        [ 0.0402,  0.0433,  0.0160,  ..., -0.0355,  0.0184, -0.0300]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in my_nn.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "institutional-library",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten\n",
      "Sequential\n"
     ]
    }
   ],
   "source": [
    "for layer in list(my_nn.children()):\n",
    "    print(layer.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aging-extra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.0134, -2.5389, -2.1242, -2.1624, -2.2485, -2.7625, -2.3273, -1.9217,\n",
       "        -2.7560, -2.5668])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(10)\n",
    "F.log_softmax(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prospective-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = torch.rand((1, 1, 28, 28)).flatten()\n",
    "result = my_nn(random_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "desperate-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(my_nn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "permanent-badge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0975,  0.0506,  0.0680,  0.0578, -0.0872,  0.0892, -0.0444, -0.0834,\n",
       "        -0.0241, -0.0487], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "iraqi-poison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0005,  0.0221, -0.0236,  ..., -0.0141, -0.0305,  0.0249],\n",
       "        [ 0.0344, -0.0233, -0.0211,  ..., -0.0115, -0.0301, -0.0240],\n",
       "        [ 0.0247, -0.0026, -0.0207,  ..., -0.0102,  0.0269, -0.0309],\n",
       "        ...,\n",
       "        [ 0.0273, -0.0333,  0.0321,  ..., -0.0133,  0.0271, -0.0303],\n",
       "        [-0.0016,  0.0285, -0.0001,  ..., -0.0167,  0.0185, -0.0030],\n",
       "        [ 0.0296,  0.0265,  0.0341,  ..., -0.0266, -0.0057, -0.0219]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prescribed-photographer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0005,  0.0221, -0.0236,  ..., -0.0141, -0.0305,  0.0249],\n",
       "        [ 0.0344, -0.0233, -0.0211,  ..., -0.0115, -0.0301, -0.0240],\n",
       "        [ 0.0247, -0.0026, -0.0207,  ..., -0.0102,  0.0269, -0.0309],\n",
       "        ...,\n",
       "        [ 0.0273, -0.0333,  0.0321,  ..., -0.0133,  0.0271, -0.0303],\n",
       "        [-0.0016,  0.0285, -0.0001,  ..., -0.0167,  0.0185, -0.0030],\n",
       "        [ 0.0296,  0.0265,  0.0341,  ..., -0.0266, -0.0057, -0.0219]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-beaver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
